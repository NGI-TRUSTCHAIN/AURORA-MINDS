# AURORA-MINDS
**Aurora Minds** represents a groundbreaking initiative aimed at addressing the need to early and accurately diagnose _ADHD_ in children, while prioritizing data privacy and security. In a landscape crowded with assistive technologies for _ADHD_, this project distinguishes itself by integrating robust privacy measures at its core. Existing _ADHD_ assistive technologies often overlook privacy and security concerns, leaving users vulnerable to data risks and profiling. To counter these challenges, AURORA MINDS implements a multi-layered security framework, including **Identity Management (IdM)** and **Privacy-Enhancing Technologies (PETs)**. This approach enhances data security, strictly controls access to sensitive information, and ensures compliance with data privacy regulations.

-The project leverages machine learning techniques such as federated learning and local differential privacy to protect sensitive user data during collection and analysis, aligning with GDPR requirements. 
**Aurora Minds** adopts a human-centric design approach, tailoring personal data collection from a child while s/he interacts with a serious tablet animation game to cater a unique ADHD risk assessment process.
The project benefits various stakeholders, including children, parents, educators, and clinicians. Children are examined through a specialized application supporting their behavioral unique requirements and independence. 
-Parents receive reassurance regarding data confidentiality, gaining insights into ADHD risk assessment and relevant information to provide better support. 
-Clinicians benefit from enhanced diagnosis capabilities, aided by qualitative and quantitative measurements. Access rights are carefully managed using the Privacy-ABCs (Privacy-Attribute-Based Credentials) approach, ensuring that each entity—child, parent, and clinician—receives appropriate access privileges.
By incorporating this proposal into the **TRUSTCHAIN** framework, **AURORA MINDS** elevates TRUSTCHAIN's reputation by exemplifying a steadfast commitment to data privacy and security. The emphasis on PETs and federated machine learning not only bolsters data privacy but also mitigates legal risks associated with data sharing, enhancing data quality for effective decision-making.
